# filesql

[![Go Reference](https://pkg.go.dev/badge/github.com/nao1215/filesql.svg)](https://pkg.go.dev/github.com/nao1215/filesql)
[![Go Report Card](https://goreportcard.com/badge/github.com/nao1215/filesql)](https://goreportcard.com/report/github.com/nao1215/filesql)
[![MultiPlatformUnitTest](https://github.com/nao1215/filesql/actions/workflows/unit_test.yml/badge.svg)](https://github.com/nao1215/filesql/actions/workflows/unit_test.yml)
![Coverage](https://raw.githubusercontent.com/nao1215/octocovs-central-repo/main/badges/nao1215/filesql/coverage.svg)

[English](../../README.md) | [–†—É—Å—Å–∫–∏–π](../ru/README.md) | [‰∏≠Êñá](../zh-cn/README.md) | [ÌïúÍµ≠Ïñ¥](../ko/README.md) | [Espa√±ol](../es/README.md) | [Êó•Êú¨Ë™û](../ja/README.md)

![logo](../image/filesql-logo.png)

**filesql** est un pilote SQL Go qui vous permet d'interroger les fichiers CSV, TSV, LTSV, Parquet et Excel (XLSX) en utilisant la syntaxe SQL de SQLite3. Interrogez directement vos fichiers de donn√©es sans importation ou transformation !

**Vous voulez d√©couvrir les capacit√©s de filesql ?** Essayez **[sqly](https://github.com/nao1215/sqly)** - un outil en ligne de commande qui utilise filesql pour ex√©cuter facilement des requ√™tes SQL sur les fichiers CSV, TSV, LTSV et Excel directement depuis votre shell ! C'est le moyen parfait de d√©couvrir la puissance de filesql en action !

## üéØ Pourquoi filesql ?

Cette biblioth√®que est n√©e de l'exp√©rience de maintenir deux outils CLI s√©par√©s - [sqly](https://github.com/nao1215/sqly) et [sqluv](https://github.com/nao1215/sqluv). Les deux outils partageaient une caract√©ristique commune : ex√©cuter des requ√™tes SQL sur les fichiers CSV, TSV et autres formats.

Plut√¥t que de maintenir du code dupliqu√© dans les deux projets, nous avons extrait la fonctionnalit√© principale dans ce pilote SQL r√©utilisable. Maintenant, tout d√©veloppeur Go peut tirer parti de cette capacit√© dans ses propres applications !

## ‚ú® Fonctionnalit√©s

- üîç **Interface SQL SQLite3** - Utilisez le puissant dialecte SQL de SQLite3 pour interroger vos fichiers
- üìÅ **Formats de fichiers multiples** - Support pour les fichiers CSV, TSV, LTSV, Parquet et Excel (XLSX)
- üóúÔ∏è **Support de compression** - G√®re automatiquement les fichiers compress√©s .gz, .bz2, .xz et .zst
- üåä **Traitement en flux** - G√®re efficacement les gros fichiers gr√¢ce au streaming avec des tailles de chunk configurables
- üìñ **Sources d'entr√©e flexibles** - Support pour les chemins de fichiers, r√©pertoires, io.Reader et embed.FS
- üöÄ **Configuration z√©ro** - Aucun serveur de base de donn√©es requis, tout fonctionne en m√©moire
- üíæ **Sauvegarde automatique** - Persiste automatiquement les modifications dans les fichiers
- üåç **Multi-plateforme** - Fonctionne parfaitement sur Linux, macOS et Windows
- ‚ö° **Propuls√© par SQLite3** - Construit sur le moteur SQLite3 robuste pour un traitement SQL fiable

## üìã Formats de fichiers support√©s

| Extension | Format | Description |
|-----------|--------|-------------|
| `.csv` | CSV | Valeurs s√©par√©es par des virgules |
| `.tsv` | TSV | Valeurs s√©par√©es par des tabulations |
| `.ltsv` | LTSV | Valeurs √©tiquet√©es s√©par√©es par des tabulations |
| `.parquet` | Parquet | Format columnaire Apache Parquet |
| `.xlsx` | Excel XLSX | Format de classeur Microsoft Excel |
| `.csv.gz`, `.tsv.gz`, `.ltsv.gz`, `.parquet.gz`, `.xlsx.gz` | Compression Gzip | Fichiers compress√©s Gzip |
| `.csv.bz2`, `.tsv.bz2`, `.ltsv.bz2`, `.parquet.bz2`, `.xlsx.bz2` | Compression Bzip2 | Fichiers compress√©s Bzip2 |
| `.csv.xz`, `.tsv.xz`, `.ltsv.xz`, `.parquet.xz`, `.xlsx.xz` | Compression XZ | Fichiers compress√©s XZ |
| `.csv.zst`, `.tsv.zst`, `.ltsv.zst`, `.parquet.zst`, `.xlsx.zst` | Compression Zstandard | Fichiers compress√©s Zstandard |

## üì¶ Installation

```bash
go get github.com/nao1215/filesql
```

## üîß Configuration requise

- **Version Go**: 1.24 ou ult√©rieure
- **Syst√®mes d'exploitation support√©s**:
  - Linux
  - macOS  
  - Windows

## üöÄ D√©marrage rapide

### Usage simple

La fa√ßon recommand√©e de commencer est avec `OpenContext` pour une gestion appropri√©e des timeouts :

```go
package main

import (
    "context"
    "fmt"
    "log"
    "time"
    
    "github.com/nao1215/filesql"
)

func main() {
    // Cr√©er un contexte avec timeout pour les op√©rations sur gros fichiers
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    // Ouvrir un fichier CSV comme base de donn√©es
    db, err := filesql.OpenContext(ctx, "data.csv")
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()
    
    // Interroger les donn√©es (nom de table = nom de fichier sans extension)
    rows, err := db.QueryContext(ctx, "SELECT * FROM data WHERE age > 25")
    if err != nil {
        log.Fatal(err)
    }
    defer rows.Close()
    
    // Traiter les r√©sultats
    for rows.Next() {
        var name string
        var age int
        if err := rows.Scan(&name, &age); err != nil {
            log.Fatal(err)
        }
        fmt.Printf("Nom: %s, √Çge: %d\n", name, age)
    }
}
```

### Fichiers multiples et formats

```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

// Ouvrir plusieurs fichiers √† la fois (incluant Parquet)
db, err := filesql.OpenContext(ctx, "users.csv", "orders.tsv", "logs.ltsv.gz", "analytics.parquet")
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Joindre les donn√©es de diff√©rents formats de fichiers
rows, err := db.QueryContext(ctx, `
    SELECT u.name, o.order_date, l.event, a.metrics
    FROM users u
    JOIN orders o ON u.id = o.user_id
    JOIN logs l ON u.id = l.user_id
    JOIN analytics a ON u.id = a.user_id
    WHERE o.order_date > '2024-01-01'
`)
```

### Travailler avec des r√©pertoires

```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

// Charger tous les fichiers support√©s d'un r√©pertoire (r√©cursivement)
db, err := filesql.OpenContext(ctx, "/path/to/data/directory")
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Voir quelles tables sont disponibles
rows, err := db.QueryContext(ctx, "SELECT name FROM sqlite_master WHERE type='table'")
```

## üîß Usage avanc√©

### Motif Builder

Pour les sc√©narios avanc√©s, utilisez le motif builder :

```go
package main

import (
    "context"
    "embed"
    "log"
    
    "github.com/nao1215/filesql"
)

//go:embed data/*.csv
var embeddedFiles embed.FS

func main() {
    ctx := context.Background()
    
    // Configurer les sources de donn√©es avec le builder
    validatedBuilder, err := filesql.NewBuilder().
        AddPath("local_file.csv").      // Fichier local
        AddFS(embeddedFiles).           // Fichiers int√©gr√©s
        SetDefaultChunkSize(5000). // 5000 lignes par chunk
        Build(ctx)
    if err != nil {
        log.Fatal(err)
    }
    
    db, err := validatedBuilder.Open(ctx)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()
    
    // Interroger toutes les sources de donn√©es
    rows, err := db.QueryContext(ctx, "SELECT name FROM sqlite_master WHERE type='table'")
    if err != nil {
        log.Fatal(err)
    }
    defer rows.Close()
}
```

### Fonctionnalit√©s de sauvegarde automatique

#### Sauvegarde automatique √† la fermeture de la base de donn√©es

```go
// Sauvegarder automatiquement les modifications √† la fermeture de la base de donn√©es
validatedBuilder, err := filesql.NewBuilder().
    AddPath("data.csv").
    EnableAutoSave("./backup"). // Sauvegarder dans le r√©pertoire de sauvegarde
    Build(ctx)
if err != nil {
    log.Fatal(err)
}

db, err := validatedBuilder.Open(ctx)
if err != nil {
    log.Fatal(err)
}
defer db.Close() // Les modifications sont automatiquement sauvegard√©es ici

// Effectuer des modifications
db.Exec("UPDATE data SET status = 'processed' WHERE id = 1")
db.Exec("INSERT INTO data (name, age) VALUES ('Jean', 30)")
```

#### Sauvegarde automatique lors du commit de transaction

```go
// Sauvegarder automatiquement apr√®s chaque transaction
validatedBuilder, err := filesql.NewBuilder().
    AddPath("data.csv").
    EnableAutoSaveOnCommit(""). // Vide = √©craser les fichiers originaux
    Build(ctx)
if err != nil {
    log.Fatal(err)
}

db, err := validatedBuilder.Open(ctx)
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Les modifications sont sauvegard√©es apr√®s chaque commit
tx, _ := db.Begin()
tx.Exec("UPDATE data SET status = 'processed' WHERE id = 1")
tx.Commit() // La sauvegarde automatique se produit ici
```

### Travailler avec io.Reader et donn√©es r√©seau

```go
import (
    "net/http"
    "github.com/nao1215/filesql"
)

// Charger des donn√©es depuis une r√©ponse HTTP
resp, err := http.Get("https://example.com/data.csv")
if err != nil {
    log.Fatal(err)
}
defer resp.Body.Close()

validatedBuilder, err := filesql.NewBuilder().
    AddReader(resp.Body, "remote_data", filesql.FileTypeCSV).
    Build(ctx)
if err != nil {
    log.Fatal(err)
}

db, err := validatedBuilder.Open(ctx)
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Interroger les donn√©es distantes
rows, err := db.QueryContext(ctx, "SELECT * FROM remote_data LIMIT 10")
```

### Exportation manuelle de donn√©es

Si vous pr√©f√©rez un contr√¥le manuel sur la sauvegarde :

```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

db, err := filesql.OpenContext(ctx, "data.csv")
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Effectuer des modifications
db.Exec("UPDATE data SET status = 'processed'")

// Exporter manuellement les modifications
err = filesql.DumpDatabase(db, "./output")
if err != nil {
    log.Fatal(err)
}

// Ou avec format et compression personnalis√©s
options := filesql.NewDumpOptions().
    WithFormat(filesql.OutputFormatTSV).
    WithCompression(filesql.CompressionGZ)
err = filesql.DumpDatabase(db, "./output", options)

// Exporter au format Parquet (lorsque disponible)
parquetOptions := filesql.NewDumpOptions().
    WithFormat(filesql.OutputFormatParquet)
// Note: L'exportation Parquet est impl√©ment√©e (compression externe non support√©e, utilisez la compression int√©gr√©e de Parquet)
```

## üìù R√®gles de nommage des tables

filesql d√©rive automatiquement les noms de tables des chemins de fichiers :

- `users.csv` ‚Üí table `users`
- `data.tsv.gz` ‚Üí table `data`
- `/path/to/sales.csv` ‚Üí table `sales`
- `products.ltsv.bz2` ‚Üí table `products`
- `analytics.parquet` ‚Üí table `analytics`

## ‚ö†Ô∏è Notes importantes

### Syntaxe SQL
Puisque filesql utilise SQLite3 comme moteur sous-jacent, toute la syntaxe SQL suit le [dialecte SQL de SQLite3](https://www.sqlite.org/lang.html). Cela inclut :
- Fonctions (ex., `date()`, `substr()`, `json_extract()`)
- Fonctions de fen√™tre
- Expressions de table communes (CTE)
- D√©clencheurs et vues

### Modifications de donn√©es
- Les op√©rations `INSERT`, `UPDATE` et `DELETE` affectent la base de donn√©es en m√©moire
- **Les fichiers originaux restent inchang√©s par d√©faut**
- Utilisez les fonctionnalit√©s de sauvegarde automatique ou `DumpDatabase()` pour persister les modifications
- Cela rend s√ªr l'exp√©rimentation avec les transformations de donn√©es

### Conseils de performance
- Utilisez `OpenContext()` avec des timeouts pour les gros fichiers
- Configurez les tailles de chunk (lignes par chunk) avec `SetDefaultChunkSize()` pour l'optimisation m√©moire
- Une seule connexion SQLite fonctionne mieux pour la plupart des sc√©narios
- Utilisez le streaming pour les fichiers plus grands que la m√©moire disponible

### Limitations de concurrence
‚ö†Ô∏è **IMPORTANT** : Cette biblioth√®que **N'EST PAS thread-safe** et a des **limitations de concurrence** :
- **NE** partagez **PAS** les connexions de base de donn√©es entre les goroutines
- **NE** effectuez **PAS** d'op√©rations concurrentes sur la m√™me instance de base de donn√©es
- **NE** appelez **PAS** `db.Close()` pendant que des requ√™tes sont actives dans d'autres goroutines
- Utilisez des instances de base de donn√©es s√©par√©es pour les op√©rations concurrentes si n√©cessaire
- Les conditions de course peuvent causer des fautes de segmentation ou une corruption de donn√©es

**Mod√®le recommand√© pour l'acc√®s concurrent** :
```go
// ‚úÖ BON : Instances de base de donn√©es s√©par√©es par goroutine
func processFileConcurrently(filename string) error {
    db, err := filesql.Open(filename)  // Chaque goroutine obtient sa propre instance
    if err != nil {
        return err
    }
    defer db.Close()
    
    // S√ªr √† utiliser dans cette goroutine
    return processData(db)
}

// ‚ùå MAUVAIS : Partager une instance de base de donn√©es entre les goroutines
var sharedDB *sql.DB  // Cela causera des conditions de course
```

### Support Parquet
- **Lecture** : Support complet pour les fichiers Apache Parquet avec des types de donn√©es complexes
- **√âcriture** : La fonctionnalit√© d'exportation est impl√©ment√©e (compression externe non support√©e, utilisez la compression int√©gr√©e de Parquet)
- **Mappage des types** : Les types Parquet sont mapp√©s vers les types SQLite
- **Compression** : La compression int√©gr√©e de Parquet est utilis√©e au lieu de la compression externe
- **Gros volumes de donn√©es** : Les fichiers Parquet sont trait√©s efficacement avec le format columnaire d'Arrow

### Support Excel (XLSX)
- **Structure 1-feuille-1-table** : Chaque feuille d'un classeur Excel devient une table SQL s√©par√©e
- **Nommage des tables** : Les noms de tables SQL suivent le format `{nomfichier}_{nomfeuille}` (ex., "ventes_T1", "ventes_T2")
- **Traitement des en-t√™tes** : La premi√®re ligne de chaque feuille devient les en-t√™tes de colonnes pour cette table
- **Op√©rations SQL standard** : Interrogez chaque feuille ind√©pendamment ou utilisez des JOIN pour combiner les donn√©es entre les feuilles
- **Exigences m√©moire** : Les fichiers XLSX n√©cessitent un chargement complet en m√©moire en raison de la structure du format bas√© sur ZIP, m√™me lors des op√©rations de streaming
- **Chargement complet en m√©moire** : Les fichiers XLSX sont enti√®rement charg√©s en m√©moire en raison de leur structure ZIP, et toutes les feuilles sont trait√©es (pas seulement la premi√®re). Les analyseurs en streaming CSV/TSV ne s'appliquent pas aux fichiers XLSX
- **Fonctionnalit√© d'exportation** : Lors de l'exportation au format XLSX, les noms de tables deviennent automatiquement des noms de feuilles
- **Support de compression** : Support complet pour les fichiers XLSX compress√©s (.xlsx.gz, .xlsx.bz2, .xlsx.xz, .xlsx.zst)

#### Exemple de structure de fichier Excel
```
Fichier Excel avec plusieurs feuilles :

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Feuille1    ‚îÇ    ‚îÇ Feuille2    ‚îÇ    ‚îÇ Feuille3    ‚îÇ
‚îÇ Nom    √Çge  ‚îÇ    ‚îÇ Produit     ‚îÇ    ‚îÇ R√©gion      ‚îÇ
‚îÇ Alice   25  ‚îÇ    ‚îÇ Portable    ‚îÇ    ‚îÇ Nord        ‚îÇ
‚îÇ Pierre  30  ‚îÇ    ‚îÇ Souris      ‚îÇ    ‚îÇ Sud         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

R√©sulte en 3 tables SQL s√©par√©es :

ventes_Feuille1:        ventes_Feuille2:        ventes_Feuille3:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Nom  ‚îÇ √Çge ‚îÇ          ‚îÇ Produit ‚îÇ             ‚îÇ R√©gion ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§          ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Alice‚îÇ  25 ‚îÇ          ‚îÇPortable ‚îÇ             ‚îÇ Nord   ‚îÇ
‚îÇPierre‚îÇ  30 ‚îÇ          ‚îÇ Souris  ‚îÇ             ‚îÇ Sud    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Exemples SQL :
SELECT * FROM ventes_Feuille1 WHERE √Çge > 27;
SELECT f1.Nom, f2.Produit FROM ventes_Feuille1 f1 
  JOIN ventes_Feuille2 f2 ON f1.rowid = f2.rowid;
```

## üé® Exemples avanc√©s

### Requ√™tes SQL complexes

```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

db, err := filesql.OpenContext(ctx, "employees.csv", "departments.csv")
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Utiliser les fonctionnalit√©s avanc√©es de SQLite
query := `
    WITH dept_stats AS (
        SELECT 
            department_id,
            AVG(salary) as avg_salary,
            COUNT(*) as emp_count
        FROM employees
        GROUP BY department_id
    )
    SELECT 
        e.name,
        e.salary,
        d.name as department,
        ds.avg_salary as dept_avg,
        RANK() OVER (PARTITION BY e.department_id ORDER BY e.salary DESC) as salary_rank
    FROM employees e
    JOIN departments d ON e.department_id = d.id
    JOIN dept_stats ds ON e.department_id = ds.department_id
    WHERE e.salary > ds.avg_salary * 0.8
    ORDER BY d.name, salary_rank
`

rows, err := db.QueryContext(ctx, query)
```

### Contexte et annulation

```go
import (
    "context"
    "time"
)

// D√©finir un timeout pour les op√©rations sur gros fichiers
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
defer cancel()

db, err := filesql.OpenContext(ctx, "huge_dataset.csv.gz")
if err != nil {
    log.Fatal(err)
}
defer db.Close()

// Requ√™te avec contexte pour le support d'annulation
rows, err := db.QueryContext(ctx, "SELECT * FROM huge_dataset WHERE status = 'active'")
```

## ü§ù Contribuer

Les contributions sont bienvenues ! Veuillez consulter le [Guide de Contribution](../../CONTRIBUTING.md) pour plus de d√©tails.

## üíñ Support

Si vous trouvez ce projet utile, veuillez consid√©rer :

- ‚≠ê Lui donner une √©toile sur GitHub - cela aide les autres √† d√©couvrir le projet
- üíù [Devenir sponsor](https://github.com/sponsors/nao1215) - votre support maintient le projet vivant et motive le d√©veloppement continu

Votre support, que ce soit par des √©toiles, des parrainages ou des contributions, est ce qui fait avancer ce projet. Merci !

## üìÑ Licence

Ce projet est sous licence MIT - consultez le fichier [LICENSE](../../LICENSE) pour plus de d√©tails.